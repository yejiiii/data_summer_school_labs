{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twython import Twython \n",
    "from collections import Counter\n",
    "\n",
    "CONSUMER_KEY =\"yQDQPSOCEuJxLBkHAI18m9bQe\" \n",
    "CONSUMER_SECRET = \"BZT763KaLxPUyd0UW8PKs7M8JRvt3RUaCNvhBwwzzPoey7zmGz\"\n",
    "ACCESS_TOKEN=\"127161897-o1gC519LMaVy5GCwhdYbmK8GX8ZSSx7Sxsrd0CYl\"\n",
    "ACCESS_TOKEN_SECRET=\"oFYNdTcBQVty0jsbC437UuEocABnUmenm6rW3WmCYcGf2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import re\n",
    "\n",
    "tweets = []          \n",
    "class MyStreamer(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        # only want to collect English-language tweets\n",
    "        if 'text' in data:\n",
    "            if data['lang'] == 'en':\n",
    "                p = re.compile('(http[s]?(://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+)?)|(via)?\\s(by)?\\s?@\\w+.|RT|&amp;|\\n|#|[^0-9^a-z^A-Z^\\s]')\n",
    "                text_RE = (p.sub(\"\", data['text'])).strip()\n",
    "                if text_RE not in tweets:\n",
    "                    tweets.append(text_RE.lower())\n",
    "                    print(len(tweets), text_RE)\n",
    "                    print(\" \")\n",
    "\n",
    "        # stop when we've collected enough\n",
    "        if len(tweets) > 100:\n",
    "            self.disconnect()\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "stream.statuses.filter(track=['galaxy note 7'])\n",
    "stream.statuses.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On the attack Surbitonsin silver medal position in Nacra 17 class',\n",
       " 'New Basketball TEAM USA 2016 Rio TShirt de Janeiro Olympics Fan Tee shirt 4',\n",
       " 'History in RioSimone Manuel becomes the first black woman to win gold in an individual swimming event Rio2016 ht',\n",
       " 'Rio 2016 We Have No Clothes To Prevent Us From Cold  Nigerian Athletes Cry Out',\n",
       " 'nytimes After rehab Michael Phelps said he was not fixated on medals in Rio The journey was personal',\n",
       " 'Daily Beast withdraws story about gay dating at Rio Games',\n",
       " 'Geno Auriemma We live in that Trumpian era where its OK to be sexist',\n",
       " 'Rio Olympics QF What time does Rafael Nadal play against Thomaz Bellucci',\n",
       " 'Thank you for your support Fiji Mens 7s team wins Gold in Rio The first ever medal for our nation TosoViti',\n",
       " 'The Truth About Rio Olympics 2016  Genetic Culling of the New World Order Doping Rio 2016',\n",
       " 'Gay Olympian Amini Fonua lashes out against the Daily Beats Grindr in Rio story']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "resultFile = open(\"output.csv\",'w',newline='')\n",
    "wr = csv.writer(resultFile)\n",
    "for item in tweets:\n",
    "     wr.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    result = []\n",
    "    for line in open('./output.csv', 'r').readlines():\n",
    "        result += line.split(\" \")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The', 'win', 'Manuel', 'lashes', 'New', 'Doping', 'he', 'USA', 'nytimes', 'Auriemma', 'On', 'our', 'withdraws', 'sexist', 'Thank', 'gay', 'against', 'rehab', 'ht', 'in', 'medal', 'Athletes', 'shirt', 'Rio', 'Michael', 'event', 'team', 'Phelps', 'for', 'of', 'black', 'Prevent', 'an', 'becomes', 'support', 'Beast', 'Genetic', 'gold', '17', 'World', 'Cold', 'Thomaz', 'History', 'Bellucci', 'attack', 'dating', 'TEAM', 'on', 'not', 'QF', 'first', 'about', 'Nadal', 'medals', 'RioSimone', 'class', 'Olympics', '4', 'TosoViti', 'where', 'Olympian', 'that', 'Truth', 'out', 'Tee', 'ever', 'personal', 'To', 'time', 'at', 'to', 'After', 'Fan', 'Daily', '2016', 'its', 'Us', 'Fonua', 'Out', 'Rafael', 'About', 'Order', 'Grindr', 'swimming', 'OK', 'Gay', 'Nacra', 'story', 'you', 'Games', 'live', 'Fiji', 'We', 'Culling', 'fixated', 'Beats', 'Mens', '7s', 'woman', 'Geno', 'From', 'era', 'your', 'Nigerian', 'Trumpian', 'What', 'the', 'does', 'was', 'Rio2016', 'Cry', 'said', 'Gold', 'individual', 'Surbitonsin', 'Have', 'de', 'nation', 'position', 'journey', 'Janeiro', 'Clothes', 'be', 'No', 'Basketball', 'play', 'wins', 'Amini', 'TShirt', 'silver'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = get_stop_words()\n",
    "for i in stop_words:\n",
    "    if '\\n' in i:\n",
    "        stop_words.remove(i)\n",
    "        stop_words.append(\"\".join(i.split('\\n')))\n",
    "print(set(i for i in stop_words if i.strip()!=\"\")) #strip 양쪽 공백 없애기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#twitter = Twython(CONSUMER_KEY,CONSUMER_SECRET,ACCESS_TOKEN,ACCESS_TOKEN_SECRET)\n",
    "#a = 10000\n",
    "#f = 1\n",
    "#tweets = twitter.search(q='일베', count=a)\n",
    "\n",
    "#from pprint import pprint\n",
    "##a = tweets['statuses'].index('text')\n",
    "#c = []\n",
    "#for i in range(a):\n",
    "    #c.append(tweets['statuses'][i]['text'])\n",
    "#    f += 1\n",
    "#    pprint(tweets['statuses'][i]['text'])\n",
    "#    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for tweet in tweets:\n",
    "#    for hashtag in tweet[\"entities\"][\"hashtags\"] :\n",
    "#        top_hashtags = Counter(hashtag['text'].lower())\n",
    "#        print(top_hashtags.most_common(5))           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
